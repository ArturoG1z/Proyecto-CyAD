{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de datos posterior al agrupamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar un arbol de decisión para determinar las variables más importantes para el clustering y la precisión del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff74812454c4e9f8f3dd45cd04a52ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Archivo:', options=(('Seleccionar archivo', None), ('02_clursters_df_previo_imputacion_n…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "%pip install -q ipywidgets\n",
    "import ipywidgets as widgets\n",
    "\n",
    "directorio = '../Results'\n",
    "# directorio = '/content'\n",
    "\n",
    "# Leer archivos xlsx dentro de la carpeta Data\n",
    "files = os.listdir(directorio)\n",
    "files = [f for f in files if f.endswith('.xlsx')]\n",
    "\n",
    "# Seleccionar archivo a leer\n",
    "dropdown = widgets.Dropdown(\n",
    "  options=[('Seleccionar archivo', None)] + [(f, f) for f in files],\n",
    "  description='Archivo:',\n",
    "  disabled=False,\n",
    ")\n",
    "nombre_archivo = '';\n",
    "def on_change(change):\n",
    "  if change['type'] == 'change' and change['name'] == 'value':\n",
    "    if change['new'] is not None:\n",
    "      global nombre_archivo\n",
    "      nombre_archivo = change['new']\n",
    "      print('Archivo seleccionado:', nombre_archivo)\n",
    "\n",
    "dropdown.observe(on_change)\n",
    "display(dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "ruta = os.path.join(directorio, nombre_archivo)\n",
    "\n",
    "# Data split y seleccion de modelos\n",
    "dataset = pd.read_excel(ruta)\n",
    "\n",
    "X = dataset.drop(columns=['cluster_kmeans', 'cluster_hc', 'Comunidad'])\n",
    "y = dataset['cluster_kmeans']\n",
    "display(X.head())\n",
    "display(y.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver balance de clases\n",
    "print(y.value_counts())\n",
    "# histograma de clases\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir el dataset en train y test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Identificar variables categóricas y numéricas\n",
    "numerical_features = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_features = X.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "# importar pipeline, column transformer y gridsearch\n",
    "# from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Preprocesamiento\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "# from sklearn.impute import SimpleImputer ya no es necesario por que l\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "# Crear un pipeline para preprocesar los datos\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "  ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "  ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combinar los preprocesadores\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "  ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "  ('preprocessor', preprocessor),\n",
    "  ('smote', SMOTE(sampling_strategy='auto', random_state=42)),\n",
    "  ('classifier', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "# Definir los hiperparámetros a buscar\n",
    "param_grid = {\n",
    "  'classifier__max_depth': [None, 5, 10, 15, 20],\n",
    "  'classifier__min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Definir el esquema de validación cruzada (StratifiedKFold)\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizar la búsqueda en cuadrícula con validación cruzada en el pipeline\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Ajustar los datos usando GridSearchCV\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Ajustar el mejor modelo en los datos de entrenamiento\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\\n\", best_params, '\\n')\n",
    "\n",
    "# Predecir los datos de prueba\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy, '\\n')\n",
    "\n",
    "# Calcular la precisión\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "print(\"Precision:\", precision, '\\n')\n",
    "\n",
    "# Calcular el reporte de clasificación\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "print(\"Classification Report:\\n\", class_report)\n",
    "\n",
    "# Calcular la matriz de confusión\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=best_model.classes_)\n",
    "disp.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# usando los mejores hiperparámetros\n",
    "# Best Hyperparameters: {'classifier__max_depth': 10, 'classifier__min_samples_split': 5}\n",
    "clf = DecisionTreeClassifier(max_depth=10, min_samples_split=5)\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "  transformers=[\n",
    "    ('num', numerical_transformer, numerical_features),\n",
    "    ('cat', categorical_transformer, categorical_features)\n",
    "  ])\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "  ('preprocessor', preprocessor),\n",
    "  ('smote', SMOTE(sampling_strategy='auto', random_state=42)),\n",
    "  ('classifier', clf)\n",
    "])\n",
    "\n",
    "# Calcular la precisión usando validación cruzada\n",
    "scores = cross_val_score(pipeline, X, y, cv=stratified_kfold, scoring='accuracy')\n",
    "\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "# Matriz de confusión\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "# X_train, X_test, y_train, y_test \n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=pipeline.classes_)\n",
    "disp.plot()\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evalauamos en el train set solo para ver que no quedó sobreajustado\n",
    "train_accuracy = best_model.score(X_train, y_train)\n",
    "print(\"Train Accuracy:\", train_accuracy)\n",
    "\n",
    "# Evaluamos en el test set para ver como generaliza\n",
    "test_accuracy = best_model.score(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las variables más importantes\n",
    "importances = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Ordenamos las importancias de mayor a menor\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Obtenemos los nombres de las columnas\n",
    "columnas = X_train.columns\n",
    "display(columnas)\n",
    "# Mostramos las 10 variables más importantes\n",
    "for i in range(5):\n",
    "    print(f\"{columnas[indices[i]]}: {importances[indices[i]]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
